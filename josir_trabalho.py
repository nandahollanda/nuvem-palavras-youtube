# -*- coding: utf-8 -*-
"""JOSIR TRABALHO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1__oQVjCNOgrSq2pMCDhFwmd7pubcxk3b
"""

# Instalar bibliotecas
!pip install google-api-python-client wordcloud matplotlib pandas

# Importar bibliotecas
from googleapiclient.discovery import build
import pandas as pd
import re
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Funções principais
def buscar_videos(chave_api, termo, max_resultados=5):
    youtube = build('youtube', 'v3', developerKey=chave_api)
    resposta = youtube.search().list(q=termo, part='id', type='video', maxResults=max_resultados).execute()
    video_ids = [item['id']['videoId'] for item in resposta['items']]
    return video_ids

def coletar_comentarios(youtube, video_id):
    comentarios = []
    resposta = youtube.commentThreads().list(
        part='snippet',
        videoId=video_id,
        textFormat='plainText',
        maxResults=100
    ).execute()

    for item in resposta['items']:
        comentario = item['snippet']['topLevelComment']['snippet']['textDisplay']
        comentarios.append(comentario)

        if item['snippet']['totalReplyCount'] > 0:
            comentarios += get_comment_replies(youtube, item['id'])

    return comentarios

def get_comment_replies(youtube, parent_id):
    respostas = []
    resposta = youtube.comments().list(
        part='snippet',
        parentId=parent_id,
        textFormat='plainText',
        maxResults=50
    ).execute()

    for item in resposta['items']:
        resposta_texto = item['snippet']['textDisplay']
        respostas.append(resposta_texto)
    return respostas

def processar_texto(lista_comentarios):
    texto = " ".join(lista_comentarios).lower()
    texto = re.sub(r"http\S+|www\S+|[^a-zA-ZÀ-ÿ\s]", "", texto)
    palavras = texto.split()
    stopwords = set(pd.read_csv('https://raw.githubusercontent.com/stopwords-iso/stopwords-pt/master/stopwords-pt.txt', header=None)[0].tolist())
    palavras_filtradas = [p for p in palavras if p not in stopwords]
    return palavras_filtradas

def gerar_nuvem(palavras):
    texto = " ".join(palavras)
    nuvem = WordCloud(width=800, height=400, background_color='white').generate(texto)
    return nuvem

# Entrada do usuário
chave_api = input("Cole aqui sua chave da API do YouTube: AIzaSyAziHDNILJUujR7rt-tZq4V1QUsX-iaZI8 ")
termo = input("Digite uma palavra-chave para buscar (ex: 'música brasileira'): ")

# Executar a coleta e mostrar resultado
youtube = build('youtube', 'v3', developerKey=chave_api)
video_ids = buscar_videos(chave_api, termo)
todos_comentarios = []

for vid in video_ids:
    todos_comentarios += coletar_comentarios(youtube, vid)

if not todos_comentarios:
    print("Nenhum comentário encontrado.")
else:
    palavras = processar_texto(todos_comentarios)
    nuvem = gerar_nuvem(palavras)

    # Mostrar a nuvem
    plt.figure(figsize=(12, 6))
    plt.imshow(nuvem, interpolation='bilinear')
    plt.axis('off')
    plt.title(f'Nuvem de Palavras para "{termo}"')
    plt.show()

    # Mostrar a tabela de palavras
    contagem = pd.Series(palavras).value_counts().reset_index()
    contagem.columns = ['Palavra', 'Frequência']
    print("\nTop 20 palavras mais frequentes:\n")
    print(contagem.head(20))